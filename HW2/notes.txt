Testing various activation functions we didn't find big improvements.
Improvement by:
- increasing # neurons per layer
- balancing the train - validation dataset ratio to 90-10. In this case the accuracy is less subject to random effects in the validation set.

layers = [200, 200, 100]
num_training = 45000
num_validation = 5000
loss = (circa) 1.0
acc = (circa) 54.2 %